# Quick Implementation Guide for Critical Test Gaps

## ðŸš€ **Immediate Priority Fixes (Next 2 Weeks)**

### **1. Frontend Test Setup (Priority 1)**

#### **Setup Jest + React Testing Library**
```bash
# In frontend directory
cd frontend
npm install --save-dev @testing-library/react @testing-library/jest-dom @testing-library/user-event jest-environment-jsdom
```

#### **Create Basic Component Tests**

```javascript
// frontend/src/components/__tests__/BusinessCaseDetailPage.test.tsx
import React from 'react';
import { render, screen, waitFor } from '@testing-library/react';
import { BusinessCaseDetailPage } from '../BusinessCaseDetailPage';
import { BrowserRouter } from 'react-router-dom';

const MockWrapper = ({ children }) => (
  <BrowserRouter>
    {children}
  </BrowserRouter>
);

describe('BusinessCaseDetailPage', () => {
  test('renders business case details', async () => {
    render(
      <MockWrapper>
        <BusinessCaseDetailPage />
      </MockWrapper>
    );
    
    await waitFor(() => {
      expect(screen.getByText(/business case/i)).toBeInTheDocument();
    });
  });
});
```

```javascript
// frontend/src/services/__tests__/AgentService.test.ts
import { AgentService } from '../AgentService';

describe('AgentService', () => {
  let agentService;
  
  beforeEach(() => {
    agentService = new AgentService();
  });
  
  test('should initialize correctly', () => {
    expect(agentService).toBeDefined();
  });
  
  test('should handle API calls correctly', async () => {
    // Mock implementation
    const mockResponse = { status: 'success' };
    jest.spyOn(global, 'fetch').mockResolvedValue({
      ok: true,
      json: jest.fn().mockResolvedValue(mockResponse)
    });
    
    const result = await agentService.initiateCase('test case');
    expect(result).toEqual(mockResponse);
  });
});
```

### **2. Database Integration Tests (Priority 1)**

```python
# backend/tests/integration/test_firestore_connection.py
import pytest
import asyncio
from google.cloud import firestore
from app.core.config import settings

class TestFirestoreConnection:
    """Test Firestore database connectivity and basic operations"""
    
    @pytest.fixture(scope="class")
    def firestore_client(self):
        """Initialize Firestore client for testing"""
        try:
            client = firestore.Client(project=settings.google_cloud_project_id)
            return client
        except Exception as e:
            pytest.skip(f"Firestore not available: {e}")
    
    def test_firestore_connection(self, firestore_client):
        """Test basic Firestore connectivity"""
        collections = list(firestore_client.collections())
        assert isinstance(collections, list)
    
    def test_business_case_crud(self, firestore_client):
        """Test basic CRUD operations on business cases collection"""
        # Create test document
        test_doc = {
            "title": "Test Case",
            "status": "INTAKE_COMPLETE",
            "created_by": "test@example.com"
        }
        
        doc_ref = firestore_client.collection("businessCases").add(test_doc)
        doc_id = doc_ref[1].id
        
        # Read document
        doc = firestore_client.collection("businessCases").document(doc_id).get()
        assert doc.exists
        assert doc.to_dict()["title"] == "Test Case"
        
        # Update document
        firestore_client.collection("businessCases").document(doc_id).update({
            "status": "PRD_DRAFTING"
        })
        
        updated_doc = firestore_client.collection("businessCases").document(doc_id).get()
        assert updated_doc.to_dict()["status"] == "PRD_DRAFTING"
        
        # Delete document
        firestore_client.collection("businessCases").document(doc_id).delete()
        deleted_doc = firestore_client.collection("businessCases").document(doc_id).get()
        assert not deleted_doc.exists
```

```python
# backend/tests/integration/test_data_model_validation.py
import pytest
from pydantic import ValidationError
from app.models.business_case import BusinessCaseData
from app.models.user import User

class TestDataModelValidation:
    """Test data model validation and constraints"""
    
    def test_business_case_model_validation(self):
        """Test BusinessCaseData model validation"""
        # Valid data
        valid_data = {
            "id": "test-case-123",
            "title": "Test Business Case",
            "status": "INTAKE_COMPLETE",
            "created_by": "test@example.com"
        }
        
        case = BusinessCaseData(**valid_data)
        assert case.title == "Test Business Case"
        assert case.status == "INTAKE_COMPLETE"
        
        # Invalid data
        with pytest.raises(ValidationError):
            BusinessCaseData(
                id="",  # Empty ID should fail
                title="Test",
                status="INVALID_STATUS"  # Invalid status
            )
    
    def test_user_model_validation(self):
        """Test User model validation"""
        valid_user = {
            "email": "test@example.com",
            "system_role": "USER"
        }
        
        user = User(**valid_user)
        assert user.email == "test@example.com"
        assert user.system_role == "USER"
        
        # Invalid email
        with pytest.raises(ValidationError):
            User(
                email="invalid-email",
                system_role="USER"
            )
```

### **3. Basic Security Tests (Priority 2)**

```python
# backend/tests/security/test_api_security.py
import pytest
import requests
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

class TestAPISecurity:
    """Test API security and authentication"""
    
    def test_protected_endpoints_require_auth(self):
        """Test that protected endpoints require authentication"""
        protected_endpoints = [
            "/api/v1/cases",
            "/api/v1/admin/users",
            "/api/v1/admin/rate-cards"
        ]
        
        for endpoint in protected_endpoints:
            response = client.get(endpoint)
            # Should return 401 Unauthorized without valid token
            assert response.status_code in [401, 403]
    
    def test_admin_endpoints_require_admin_role(self):
        """Test that admin endpoints require admin role"""
        # Mock a user token without admin role
        headers = {"Authorization": "Bearer mock-user-token"}
        
        admin_endpoints = [
            "/api/v1/admin/users",
            "/api/v1/admin/rate-cards"
        ]
        
        for endpoint in admin_endpoints:
            response = client.get(endpoint, headers=headers)
            # Should return 403 Forbidden for non-admin users
            assert response.status_code == 403
    
    def test_input_validation_prevents_injection(self):
        """Test that input validation prevents injection attacks"""
        malicious_inputs = [
            "'; DROP TABLE users; --",
            "<script>alert('xss')</script>",
            "{{7*7}}",  # Template injection
            "../../../etc/passwd"  # Path traversal
        ]
        
        for malicious_input in malicious_inputs:
            response = client.post("/api/v1/cases", json={
                "title": malicious_input,
                "description": "Test case"
            })
            
            # Should either reject or sanitize the input
            if response.status_code == 200:
                # If accepted, ensure the malicious input was sanitized
                assert malicious_input not in response.text
```

### **4. Basic Performance Tests (Priority 2)**

```python
# backend/tests/performance/test_api_response_times.py
import pytest
import time
import asyncio
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

class TestAPIPerformance:
    """Test API response times and performance"""
    
    def test_health_endpoint_response_time(self):
        """Test health endpoint responds quickly"""
        start_time = time.time()
        response = client.get("/health")
        end_time = time.time()
        
        response_time = end_time - start_time
        
        assert response.status_code == 200
        assert response_time < 1.0  # Should respond within 1 second
    
    def test_case_listing_performance(self):
        """Test case listing endpoint performance"""
        # Mock authentication header
        headers = {"Authorization": "Bearer mock-valid-token"}
        
        start_time = time.time()
        response = client.get("/api/v1/cases", headers=headers)
        end_time = time.time()
        
        response_time = end_time - start_time
        
        # API should respond within 2 seconds
        assert response_time < 2.0
    
    @pytest.mark.asyncio
    async def test_concurrent_requests(self):
        """Test system handles concurrent requests"""
        async def make_request():
            return client.get("/health")
        
        # Make 10 concurrent requests
        tasks = [make_request() for _ in range(10)]
        responses = await asyncio.gather(*tasks)
        
        # All requests should succeed
        for response in responses:
            assert response.status_code == 200
```

---

## ðŸ› ï¸ **Implementation Scripts**

### **Frontend Test Setup Script**
```bash
#!/bin/bash
# setup_frontend_tests.sh

echo "Setting up frontend testing environment..."

cd frontend

# Install testing dependencies
npm install --save-dev \
  @testing-library/react \
  @testing-library/jest-dom \
  @testing-library/user-event \
  jest-environment-jsdom

# Create test directories
mkdir -p src/components/__tests__
mkdir -p src/services/__tests__
mkdir -p src/contexts/__tests__
mkdir -p src/pages/__tests__

# Create Jest configuration
cat > jest.config.js << 'EOF'
module.exports = {
  testEnvironment: 'jsdom',
  setupFilesAfterEnv: ['<rootDir>/src/setupTests.ts'],
  moduleNameMapping: {
    '\\.(css|less|scss|sass)$': 'identity-obj-proxy',
  },
  collectCoverageFrom: [
    'src/**/*.{ts,tsx}',
    '!src/**/*.d.ts',
  ],
};
EOF

# Create setup file
cat > src/setupTests.ts << 'EOF'
import '@testing-library/jest-dom';
EOF

echo "Frontend testing setup complete!"
```

### **Backend Test Structure Script**
```bash
#!/bin/bash
# setup_backend_tests.sh

echo "Setting up backend testing structure..."

cd backend

# Create test directories
mkdir -p tests/integration
mkdir -p tests/security
mkdir -p tests/performance
mkdir -p tests/unit/agents
mkdir -p tests/unit/models
mkdir -p tests/unit/services

# Install additional testing dependencies
pip install pytest-asyncio pytest-mock pytest-cov

echo "Backend testing structure setup complete!"
```

---

## ðŸ“‹ **Immediate Action Checklist**

### **Week 1: Frontend Tests**
- [ ] Setup Jest + React Testing Library
- [ ] Create basic component tests for key pages
- [ ] Add service layer tests
- [ ] Setup test automation in package.json

### **Week 2: Database Tests**
- [ ] Create Firestore connection tests
- [ ] Add data model validation tests
- [ ] Test CRUD operations for all collections
- [ ] Add database transaction tests

### **Week 3: Security Tests**
- [ ] Add API authentication tests
- [ ] Test role-based access control
- [ ] Add input validation tests
- [ ] Test for common security vulnerabilities

### **Week 4: Performance Tests**
- [ ] Add response time validation
- [ ] Create basic load tests
- [ ] Test concurrent user scenarios
- [ ] Add memory usage monitoring

---

## ðŸŽ¯ **Success Metrics**

- **Frontend Test Coverage**: Target 80%+ of components tested
- **Database Integration**: 100% of data models validated
- **Security Testing**: All authentication flows tested
- **Performance**: All API endpoints respond < 2 seconds
- **Overall Coverage**: Increase from 70% to 85%

## ðŸ“ž **Need Help?**

Reference existing test files for patterns:
- `backend/tests/unit/test_user_roles.py` - Good unit test example
- `test_role_based_e2e.py` - E2E test pattern
- `run_role_tests.py` - Test runner pattern

**Priority**: Start with Frontend Tests and Database Integration Tests as these address the highest-risk gaps in our current coverage. 